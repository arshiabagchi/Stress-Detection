{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "LOAD MODELS AND DEPENDENCIES"
      ],
      "metadata": {
        "id": "48QQUDtUg5h_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLoJNvF3Cc-d",
        "outputId": "7ae0d0f9-4cd6-4a11-e5e0-8e9941f8a3d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "67KmZhABCzAY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "893f0e76-2f2f-4794-e00b-45759b7e107d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['survey_model.h5', 'survey_scaler.pkl', 'survey_encoder.pkl', 'C6_values.npy', 'C5_values.npy', 'C4_values.npy', 'C3_values.npy', 'C2_values.npy', 'audio_model.h5', 'facial_model.h5']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# List files in your model directory\n",
        "print(os.listdir('/content/drive/MyDrive/saved_models'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "h1FizyFLQS24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5d86494-a18c-47ba-cf65-ff35ba05f0fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "#Loads pre-trained models from model directory\n",
        "import tensorflow as tf\n",
        "facial_model = tf.keras.models.load_model(\"/content/drive/MyDrive/saved_models/facial_model.h5\") #Facial Prediction\n",
        "audio_model = tf.keras.models.load_model(\"/content/drive/MyDrive/saved_models/audio_model.h5\") #Audio Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOoxThbKDLNn"
      },
      "source": [
        "FACIAL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2ufuRLv_C9mf"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "#Function that takes an image path and loads model\n",
        "def predict_facial(photo_path, model):\n",
        "\n",
        "    \"\"\"\n",
        "    photo_path: path to the photo file\n",
        "    model: loaded keras facial model\n",
        "\n",
        "    Returns:\n",
        "        label: 'Stressed' or 'Not Stressed'\n",
        "        confidence: float, confidence for the predicted label\n",
        "    \"\"\"\n",
        "\n",
        "    # Load and preprocess image\n",
        "    #Reads the image from photo path, converts it to grayscale, resized and normalizes it\n",
        "    img = cv2.imread(photo_path)\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    resized = cv2.resize(gray, (48, 48))\n",
        "    normalized = resized / 255.0\n",
        "    input_img = normalized.reshape(1, 48, 48, 1)\n",
        "\n",
        "    # Predict\n",
        "    prediction = model.predict(input_img, verbose=0)\n",
        "    class_id = np.argmax(prediction)\n",
        "    confidence = float(prediction[0][class_id])\n",
        "    label = \"Stressed\" if class_id == 1 else \"Not Stressed\"\n",
        "    return label, confidence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cse_FC0QGoPe"
      },
      "source": [
        "SURVEY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "S89tO7YJYakO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dde2be6-ad28-4532-bab9-645eba93c7b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Load your trained model\n",
        "model = tf.keras.models.load_model('/content/drive/MyDrive/saved_models/survey_model.h5')\n",
        "\n",
        "# Load the fitted encoder and scaler\n",
        "encoder = joblib.load('/content/drive/MyDrive/saved_models/survey_encoder.pkl')\n",
        "scaler = joblib.load('/content/drive/MyDrive/saved_models/survey_scaler.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "lLyOJdyTYvIP"
      },
      "outputs": [],
      "source": [
        "# Load unique values for each question (for Gradio radio buttons)\n",
        "features = ['C2', 'C3', 'C4', 'C5', 'C6']\n",
        "choices = []\n",
        "for col in features:\n",
        "    choices.append(sorted(np.load(f\"/content/drive/MyDrive/saved_models/{col}_values.npy\", allow_pickle=True)))\n",
        "\n",
        "#Function to predict stressed/not stressed based on survey answered by the user.\n",
        "def predict_survey(activity, companion, pressure, tired, energetic):\n",
        "    user_input = pd.DataFrame([{\n",
        "        'C2': activity,\n",
        "        'C3': companion,\n",
        "        'C4': pressure,\n",
        "        'C5': tired,\n",
        "        'C6': energetic\n",
        "    }])\n",
        "    encoded = encoder.transform(user_input[features])\n",
        "    scaled = scaler.transform(encoded)\n",
        "    prediction = model.predict(scaled)[0][0]\n",
        "    label = \"Stressed\" if prediction >= 0.5 else \"Not Stressed\"\n",
        "    confidence = round(float(prediction if prediction >= 0.5 else 1 - prediction), 2)\n",
        "    return label, confidence\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLgQW3RWITON"
      },
      "source": [
        "AUDIO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XGrsMCZQSYLh"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import librosa\n",
        "\n",
        "#Audio model already loaded globally but can be loaded again.\n",
        "#audio_model = tf.keras.models.load_model('/content/drive/MyDrive/saved_models/audio_model.h5')\n",
        "\n",
        "#Function to convert the audio waveform into machine-readable 2d feature map (MFCCs)\n",
        "def extract_features(audio, sr=22050):\n",
        "    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=38)\n",
        "\n",
        "    # Pad or crop to 98 time steps\n",
        "    if mfccs.shape[1] < 98:\n",
        "        pad_width = 98 - mfccs.shape[1]\n",
        "        mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
        "    else:\n",
        "        mfccs = mfccs[:, :98]\n",
        "\n",
        "    mfccs = np.expand_dims(mfccs, axis=-1)  # (38, 98, 1)\n",
        "    return mfccs\n",
        "\n",
        "#Function to predict stress based on the MFCC made by previous function\n",
        "def predict_audio(audio_file, model=audio_model):\n",
        "    try:\n",
        "        y, sr = librosa.load(audio_file, sr=22050)\n",
        "        features = extract_features(y, sr)\n",
        "        features = features.reshape(1, 38, 98, 1)  # Input shape for CNN\n",
        "\n",
        "        prediction = model.predict(features, verbose=0)[0][0]  # Binary classification\n",
        "\n",
        "        label = \"Stressed\" if prediction >= 0.5 else \"Not Stressed\"\n",
        "        confidence = prediction if prediction >= 0.5 else 1 - prediction\n",
        "\n",
        "        return label, confidence\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Audio Prediction Error: {str(e)}\")\n",
        "        return \"Error\", 0.0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9mfce-R2LkH"
      },
      "source": [
        "FUSION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "YRwYwJkb2M78"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "#Function to get the fused(weighted) average confidence of the prediction\n",
        "def get_stress_confidence(label, confidence):\n",
        "    if label.lower() == 'stressed':\n",
        "        return float(confidence)\n",
        "    else:\n",
        "        return 1.0 - float(confidence)\n",
        "\n",
        "def agreement_fusion(confidences):\n",
        "    M = len(confidences)\n",
        "    agree_scores = []\n",
        "    for i in range(M):\n",
        "        total_agree = 0\n",
        "        for j in range(M):\n",
        "            if i != j:\n",
        "                total_agree += (1 - abs(confidences[i] - confidences[j]))\n",
        "        agree_i = total_agree / (M - 1)\n",
        "        agree_scores.append(agree_i)\n",
        "    agree_scores = np.array(agree_scores)\n",
        "    fused = np.sum(agree_scores * confidences) / np.sum(agree_scores)\n",
        "    return fused"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nqxtsQ6YVcAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# YOUR ORIGINAL PREDICTION LOGIC (UNCHANGED)\n",
        "# ---------------------------------------------------------\n",
        "def fused_stress_prediction(audio_file, photo_path,\n",
        "                            activity, companion, pressure, tired, energetic):\n",
        "\n",
        "    try:\n",
        "        print(\"üì• Inputs Received:\")\n",
        "        print(\"Audio:\", audio_file)\n",
        "        print(\"Image:\", photo_path)\n",
        "        print(\"Survey:\", activity, companion, pressure, tired, energetic)\n",
        "\n",
        "        label_audio, conf_audio = predict_audio(audio_file, audio_model)\n",
        "        label_facial, conf_facial = predict_facial(photo_path, facial_model)\n",
        "        label_survey, conf_survey = predict_survey(activity, companion, pressure, tired, energetic)\n",
        "\n",
        "        confidences = [\n",
        "            get_stress_confidence(label_audio, conf_audio),\n",
        "            get_stress_confidence(label_facial, conf_facial),\n",
        "            get_stress_confidence(label_survey, conf_survey)\n",
        "        ]\n",
        "\n",
        "        fused_score = round(agreement_fusion(confidences), 2)\n",
        "        print(f\"üîÅ Fused Stress Score: {fused_score:.2f}\")\n",
        "\n",
        "        label = \"üß† Stressed\" if fused_score >= 0.5 else \"üôÇ Not Stressed\"\n",
        "\n",
        "        return f\"{label} (Fused Score: {fused_score:.2f})\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"‚ö†Ô∏è Error: {str(e)}\"\n",
        "\n",
        "\n",
        "choices = [\n",
        "    [\"Working\", \"Studying\", \"Relaxing\", \"Exercising\", \"Other\"],\n",
        "    [\"Alone\", \"Friends\", \"Family\", \"Colleagues\", \"Strangers\"],\n",
        "    [\"Yes\", \"No\", \"Maybe\"],\n",
        "    [\"Yes\", \"No\"],\n",
        "    [\"Very Energetic\", \"Somewhat Energetic\", \"Neutral\", \"Tired\"]\n",
        "]\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# PREMIUM HEALTHCARE THEME COLORS\n",
        "# ---------------------------------------------------------\n",
        "premium_theme = gr.themes.Base(\n",
        "    primary_hue=\"teal\",\n",
        "    secondary_hue=\"blue\",\n",
        "    neutral_hue=\"gray\",\n",
        ").set(\n",
        "    body_background_fill=\"#f0f6f7\",\n",
        "    block_background_fill=\"#ffffff\",\n",
        "    block_title_text_color=\"#0d3b66\",\n",
        "    link_text_color=\"#0077b6\",\n",
        "    button_primary_background_fill=\"#1aa6b7\",\n",
        "    button_primary_text_color=\"white\",\n",
        ")\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# FULL WEBSITE UI\n",
        "# ---------------------------------------------------------\n",
        "with gr.Blocks(theme=premium_theme, css=\"\"\"\n",
        "    .fullpage {\n",
        "        width: 90%;\n",
        "        margin: auto;\n",
        "        text-align: center;\n",
        "        padding: 25px;\n",
        "    }\n",
        "    h1, h2, h3, p, li {\n",
        "        text-align: center !important;\n",
        "    }\n",
        "    .big-section {\n",
        "        max-width: 950px;\n",
        "        margin: auto;\n",
        "        font-size: 17.5px;\n",
        "        line-height: 1.9;\n",
        "    }\n",
        "    .chatbot-btn {\n",
        "        display: inline-block;\n",
        "        background: #024059;\n",
        "        padding: 12px 22px;\n",
        "        border-radius: 10px;\n",
        "        margin-top: 20px;\n",
        "        color: white !important;\n",
        "        font-weight: 600;\n",
        "        font-size: 18px;\n",
        "        text-decoration: none !important;\n",
        "    }\n",
        "    .chatbot-btn:hover {\n",
        "        background: #1aa6b7;\n",
        "    }\n",
        "\"\"\") as demo:\n",
        "\n",
        "    with gr.Tabs():\n",
        "\n",
        "        # -------------------------------------------------\n",
        "        # HOME PAGE (HIGHLY EXPANDED MEDICAL CONTENT)\n",
        "        # -------------------------------------------------\n",
        "        with gr.Tab(\"üè† Home\"):\n",
        "            gr.HTML(\"\"\"\n",
        "<div class='fullpage big-section'>\n",
        "\n",
        "<h1><b>StressAware‚Ñ¢ ‚Äì Comprehensive Multimodal Stress Assessment System</b></h1>\n",
        "\n",
        "<p>\n",
        "StressAware‚Ñ¢ is a clinically influenced AI-driven platform designed to analyze stress through\n",
        "<b>voice biomarkers</b>, <b>facial micro-expressions</b>, and <b>behavioral context</b>.\n",
        "This combined approach aligns with modern research in mental-health informatics, affective science,\n",
        "and digital well-being monitoring.\n",
        "</p>\n",
        "\n",
        "<hr>\n",
        "\n",
        "<h2><b>Understanding Stress: A Medical Perspective</b></h2>\n",
        "\n",
        "<p>\n",
        "Stress is not simply an emotional experience ‚Äî it is a measurable biological and neurological process.\n",
        "When the human body perceives threat or pressure, the <b>Hypothalamic‚ÄìPituitary‚ÄìAdrenal (HPA) axis</b> activates,\n",
        "releasing cortisol, adrenaline, and inflammatory markers.\n",
        "Over time, chronic activation leads to:\n",
        "</p>\n",
        "\n",
        "<ul style=\"text-align:center; list-style-position: inside;\">\n",
        "<li>Impaired cognitive functioning and memory dysregulation</li>\n",
        "<li>Elevated blood pressure and cardiovascular strain</li>\n",
        "<li>Disrupted sleep cycles and hormonal imbalance</li>\n",
        "<li>Reduced immune response and slower healing</li>\n",
        "<li>Increased risk of anxiety, depression, and burnout</li>\n",
        "</ul>\n",
        "\n",
        "<p>\n",
        "Modern healthcare recognizes stress as a major contributor to global disease burden.\n",
        "Both <b>WHO</b> and <b>American Psychological Association (APA)</b> recommend early detection,\n",
        "continuous monitoring, and scalable self-assessment tools.\n",
        "</p>\n",
        "\n",
        "<hr>\n",
        "\n",
        "<h2><b>Why Early Stress Detection Is Crucial</b></h2>\n",
        "\n",
        "<p>\n",
        "Early identification supports better long-term health outcomes. Research shows individuals who regularly\n",
        "monitor stress have:\n",
        "</p>\n",
        "\n",
        "<ul style=\"text-align:center; list-style-position: inside;\">\n",
        "<li>Lower risks of burnout and chronic fatigue</li>\n",
        "<li>Enhanced productivity and decision accuracy</li>\n",
        "<li>Better emotional regulation and interpersonal functioning</li>\n",
        "<li>Reduced dependence on crisis-stage mental health intervention</li>\n",
        "<li>Greater resilience and adaptive coping skills</li>\n",
        "</ul>\n",
        "\n",
        "<hr>\n",
        "\n",
        "<h2><b>Our Multimodal Approach to Stress Detection</b></h2>\n",
        "\n",
        "<p>\n",
        "Traditional stress evaluation often relies on subjective reporting.\n",
        "StressAware‚Ñ¢ enhances this process with clinically aligned observations across:\n",
        "</p>\n",
        "\n",
        "<ul style=\"text-align:center; list-style-position: inside;\">\n",
        "<li><b>Voice Analysis</b> ‚Äì detecting micro-tremors, vocal strain, pitch anomalies caused by stress hormones</li>\n",
        "<li><b>Facial Behavior</b> ‚Äì observing muscle tension, micro-expressions linked to emotional load</li>\n",
        "<li><b>Contextual Indicators</b> ‚Äì analyzing fatigue, perceived pressure, social environment, and energy levels</li>\n",
        "<li><b>Behavior‚ÄìEmotion Correlation</b> ‚Äì combining multiple modalities to provide a reliable unified stress profile</li>\n",
        "</ul>\n",
        "\n",
        "<hr>\n",
        "\n",
        "<h2><b>Evidence-Based Features of StressAware‚Ñ¢</b></h2>\n",
        "\n",
        "<p>\n",
        "Our system integrates multidisciplinary principles from:\n",
        "</p>\n",
        "\n",
        "<ul style=\"text-align:center; list-style-position: inside;\">\n",
        "<li>Affective Computing</li>\n",
        "<li>Behavioral Neuroscience</li>\n",
        "<li>Speech Signal Processing</li>\n",
        "<li>Emotional AI & Bioinformatics</li>\n",
        "<li>Digital Mental Health Frameworks</li>\n",
        "</ul>\n",
        "\n",
        "<p>\n",
        "This makes StressAware‚Ñ¢ suitable for:\n",
        "</p>\n",
        "\n",
        "<ul style=\"text-align:center; list-style-position: inside;\">\n",
        "<li>Students coping with exams and academic pressure</li>\n",
        "<li>Professionals dealing with occupational stress</li>\n",
        "<li>Athletes tracking performance anxiety</li>\n",
        "<li>Individuals engaged in wellness, therapy, or self-improvement</li>\n",
        "</ul>\n",
        "\n",
        "<p>\n",
        "Proceed to the <b>Stress Detection</b> tab to receive your real-time evaluation.\n",
        "</p>\n",
        "\n",
        "</div>\n",
        "            \"\"\")\n",
        "\n",
        "\n",
        "        # -------------------------------------------------\n",
        "        # ABOUT PAGE (EXPANDED + MEDICAL + TECHNICAL)\n",
        "        # -------------------------------------------------\n",
        "        with gr.Tab(\"üìò About the Project\"):\n",
        "            gr.HTML(\"\"\"\n",
        "<div class='fullpage big-section'>\n",
        "\n",
        "<h1><b>About the Multimodal Stress Detection System</b></h1>\n",
        "\n",
        "<p>\n",
        "This project is built on the convergence of advanced signal processing, facial affect science,\n",
        "behavioral psychology, and machine learning.\n",
        "The goal is to make stress assessment accessible, data-driven, and clinically aligned.\n",
        "</p>\n",
        "\n",
        "<hr>\n",
        "\n",
        "<h2><b>1. Voice Stress Biomarkers</b></h2>\n",
        "\n",
        "<p>\n",
        "Stress modifies the neuromuscular coordination of the vocal folds.\n",
        "Research indicates that stress hormones influence:\n",
        "</p>\n",
        "\n",
        "<ul style=\"text-align:center; list-style-position: inside;\">\n",
        "<li>Fundamental frequency (F0) instability</li>\n",
        "<li>Amplitude modulation and loudness variability</li>\n",
        "<li>Speech rate, pausing patterns, and articulation clarity</li>\n",
        "<li>Micro-tremors associated with tension</li>\n",
        "</ul>\n",
        "\n",
        "<p>\n",
        "Our voice model extracts these acoustic signatures and uses them to predict stress probability.\n",
        "</p>\n",
        "\n",
        "<hr>\n",
        "\n",
        "<h2><b>2. Facial Expression & Micro-Behavior Analysis</b></h2>\n",
        "\n",
        "<p>\n",
        "Facial muscle movements are one of the most reliable windows into affective state.\n",
        "Stress triggers involuntary changes such as:\n",
        "</p>\n",
        "\n",
        "<ul style=\"text-align:center; list-style-position: inside;\">\n",
        "<li>Brow lifting or contraction (frontalis/corrugator activity)</li>\n",
        "<li>Orbital tightening around the eyes</li>\n",
        "<li>Lip pressing, corner tightening, or asymmetry</li>\n",
        "<li>Identity-preserved micro-expressions lasting under 1/2 second</li>\n",
        "</ul>\n",
        "\n",
        "<p>\n",
        "The system uses these micro-patterns to contribute to the multimodal stress score.\n",
        "</p>\n",
        "\n",
        "<hr>\n",
        "\n",
        "<h2><b>3. Contextual Behavioral Indicators</b></h2>\n",
        "\n",
        "<p>\n",
        "True stress interpretation requires context.\n",
        "This project captures:\n",
        "</p>\n",
        "\n",
        "<ul style=\"text-align:center; list-style-position: inside;\">\n",
        "<li>Nature of current activity</li>\n",
        "<li>Social surroundings</li>\n",
        "<li>Self-reported pressure levels</li>\n",
        "<li>Fatigue indicators</li>\n",
        "<li>Energy levels indicating emotional‚Äìphysical alignment</li>\n",
        "</ul>\n",
        "\n",
        "<p>\n",
        "These factors work as behavioral co-signals to improve reliability.\n",
        "</p>\n",
        "\n",
        "<hr>\n",
        "\n",
        "<h2><b>4. Multimodal Fusion: The Core of Clinical-Grade Analysis</b></h2>\n",
        "\n",
        "<p>\n",
        "Each modality produces an independent assessment.\n",
        "The fusion mechanism then performs:\n",
        "</p>\n",
        "\n",
        "<ul style=\"text-align:center; list-style-position: inside;\">\n",
        "<li><b>Evidence aggregation</b></li>\n",
        "<li><b>Confidence weighting</b></li>\n",
        "<li><b>Cross-modal consistency checking</b></li>\n",
        "</ul>\n",
        "\n",
        "<p>\n",
        "This leads to a scientifically aligned stress probability score, similar to\n",
        "methodologies used in digital diagnostics and computational psychiatry.\n",
        "</p>\n",
        "\n",
        "<hr>\n",
        "\n",
        "<h2><b>5. Applications and Real-World Impact</b></h2>\n",
        "\n",
        "<ul style=\"text-align:center; list-style-position: inside;\">\n",
        "<li>Mental-health monitoring platforms</li>\n",
        "<li>Employee well-being systems</li>\n",
        "<li>Therapy & counseling augmentation</li>\n",
        "<li>Education ‚Äî student workload monitoring</li>\n",
        "<li>Athletic performance optimization</li>\n",
        "<li>AI-driven emotional health assistants</li>\n",
        "</ul>\n",
        "\n",
        "<p>\n",
        "The project demonstrates how multimodal AI can transform digital health assessments.\n",
        "</p>\n",
        "\n",
        "</div>\n",
        "            \"\"\")\n",
        "\n",
        "\n",
        "        # -------------------------------------------------\n",
        "        # STRESS DETECTION PAGE (unchanged except layout)\n",
        "        # -------------------------------------------------\n",
        "        with gr.Tab(\"üß™ Stress Detection\"):\n",
        "            gr.HTML(\"\"\"\n",
        "<div class='fullpage'>\n",
        "<h1><b>Stress Detection Module</b></h1>\n",
        "<p class='big-section'>\n",
        "Upload a voice sample, facial image, and your contextual information.\n",
        "Your stress score is generated in real-time using multimodal AI.\n",
        "</p>\n",
        "</div>\n",
        "            \"\"\")\n",
        "\n",
        "            output_box = gr.Textbox(label=\"üß† Stress Assessment Result\", lines=2)\n",
        "\n",
        "            # Chatbot button OUTSIDE output area\n",
        "            gr.HTML(\"\"\"\n",
        "<a class='chatbot-btn' href='http://127.0.0.1:8000/' target='_blank'>\n",
        "üí¨ Open Wellness Chatbot\n",
        "</a>\n",
        "            \"\"\")\n",
        "\n",
        "            def run_model(audio, img, a, c, p, t, e):\n",
        "                return fused_stress_prediction(audio, img, a, c, p, t, e)\n",
        "\n",
        "            inputs = [\n",
        "                gr.Audio(type=\"filepath\", label=\"üé§ Voice Input\"),\n",
        "                gr.Image(type=\"filepath\", label=\"üì∏ Facial Image\"),\n",
        "                gr.Radio(choices=choices[0], label=\"Current Activity\"),\n",
        "                gr.Radio(choices=choices[1], label=\"Who are you with?\"),\n",
        "                gr.Radio(choices=choices[2], label=\"Feeling under pressure?\"),\n",
        "                gr.Radio(choices=choices[3], label=\"Feeling tired?\"),\n",
        "                gr.Radio(choices=choices[4], label=\"Current energy level\")\n",
        "            ]\n",
        "\n",
        "            submit = gr.Button(\"Analyze Stress\")\n",
        "            submit.click(run_model, inputs, output_box)\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# LAUNCH\n",
        "# ---------------------------------------------------------\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715
        },
        "id": "XEQyyk35TEHc",
        "outputId": "1dfe99c2-73dd-4a55-8c76-f8acf52eebe0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-838106839.py:65: DeprecationWarning: The 'theme' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'theme' to Blocks.launch() instead.\n",
            "  with gr.Blocks(theme=premium_theme, css=\"\"\"\n",
            "/tmp/ipython-input-838106839.py:65: DeprecationWarning: The 'css' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'css' to Blocks.launch() instead.\n",
            "  with gr.Blocks(theme=premium_theme, css=\"\"\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://26fb35dbfd354a21fb.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://26fb35dbfd354a21fb.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}